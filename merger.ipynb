{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8c9cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "168e662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(year, out_dir):\n",
    "    # In cleanedData directory, find the year folder\n",
    "    cleaned_dir = f\"cleanedData/{year}\"\n",
    "    if not os.path.exists(cleaned_dir):\n",
    "        return\n",
    "\n",
    "    # Loop through all the files, except 'RONI' and 'temperature_anomalies' in the cleanedData/year directory and LEFT JOIN them on 'FIPS' column\n",
    "    files = [f for f in os.listdir(cleaned_dir) if f.endswith('.csv') and 'RONI' not in f and 'temperature_anomalies' not in f and 'StormData' not in f]\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(os.path.join(cleaned_dir, file))\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Merge non-special dataframes on 'FIPS' column using LEFT JOIN\n",
    "    # first df is StormData csv file\n",
    "    final_df = pd.read_csv(os.path.join(cleaned_dir, f\"StormData.csv\"))\n",
    "    for df in dfs:\n",
    "        final_df = pd.merge(final_df, df, on='FIPS', how='left')\n",
    "\n",
    "    # fill missing values in coastal type columns with 'inland'\n",
    "    final_df['COASTAL_TYPE_SHORELINE'] = final_df['COASTAL_TYPE_SHORELINE'].fillna('inland')\n",
    "    final_df['COASTAL_TYPE_WATERSHED'] = final_df['COASTAL_TYPE_WATERSHED'].fillna('inland')\n",
    "\n",
    "    # drop missing month name rows as they are propabably from merging on fips code but the merging df still has non mainland fips code which is not in the final df\n",
    "    final_df = final_df.dropna(subset=['MONTH_NAME'])\n",
    "\n",
    "    # merge temperature anomalies to the final data by matching the month number and fips code\n",
    "    # first make the month number in the final df a int and then merge on month number\n",
    "    # final_df['MONTH'] = final_df['MONTH'].astype(int)\n",
    "    anomalies_path = os.path.join(cleaned_dir, f\"temperature_anomalies.csv\")\n",
    "    temp_anomalies_df = pd.read_csv(anomalies_path)\n",
    "    final_df = pd.merge(final_df, temp_anomalies_df, on=['FIPS', 'MONTH'], how='left')\n",
    "\n",
    "    # drop missing anomalies as they are all but two from the district of columbia which is not in the anomalies df. There are no zero anomalies.\n",
    "    final_df = final_df.dropna(subset=['ANOMALY']) \n",
    "\n",
    "    # merge the RONI data on month NameError\n",
    "    # first first change the month column in the RONI df to 'MONTH_NAME' and then merge on month name\n",
    "    roni_path = os.path.join(cleaned_dir, f\"RONI.csv\")\n",
    "    roni_df = pd.read_csv(roni_path)\n",
    "    final_df = pd.merge(final_df, roni_df, on='MONTH_NAME', how='left')\n",
    "\n",
    "\n",
    "    # drop month name and month number columns\n",
    "    final_df = final_df.drop(columns=['MONTH', 'MONTH_NAME'])\n",
    "\n",
    "    # Save the final dataframe to the final directory\n",
    "    final_df.to_csv(os.path.join(out_dir, f\"mergedData_{year}.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6689d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2023\n",
    "final_dir = f\"{year}\"\n",
    "\n",
    "if not os.path.exists(final_dir):\n",
    "    os.makedirs(final_dir)\n",
    "\n",
    "merge_data(year, final_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
