{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed59de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import haversine_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b59f45f",
   "metadata": {},
   "source": [
    "Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece80777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0553817b",
   "metadata": {},
   "source": [
    "Storm Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_storm(csv):\n",
    "    df = pd.read_csv(csv)\n",
    "\n",
    "\n",
    "\n",
    "    # keep columns: first 6 columns, state, state_fips, event_type,cz_fips cz_name, damage_property, begin_lat, begin_lon, end_lat, end_lon. All names are in uppper case\n",
    "    new_df = df.iloc[:, :6]\n",
    "    join_df = df[['STATE', 'STATE_FIPS', 'EVENT_TYPE', 'CZ_FIPS', 'CZ_NAME', 'DAMAGE_PROPERTY', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON']]\n",
    "    new_df = pd.concat([new_df, join_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    # calculate the approximate area of the storm by using the haversine formula to calculate the distance between the begin and end coordinates. Add a new column called 'STORM_AREA' to the dataframe\n",
    "    # drop na values in cordinates columns\n",
    "    new_df = new_df.dropna(subset=['BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON'])\n",
    "    def rect_area(begin_lat, begin_lon, end_lat, end_lon):\n",
    "        # convert decimal degrees to radians\n",
    "        lat1, lon1, lat2, lon2 = map(np.radians, [begin_lat, begin_lon, end_lat, end_lon])\n",
    "\n",
    "        # use A = R² (sin lat1 − sin lat2) (lon1 − lon2).\n",
    "        # from https://www.johndcook.com/blog/2023/02/21/sphere-grid-area/#:~:text=Area%20of%20latitude/longitude%20grid&text=A%20=%20π%20R²%20(sin%20φ,1%20−%20θ2)/180.\n",
    "        r = 3956  # Radius of earth in miles\n",
    "        area = r**2 * (np.sin(lat1) - np.sin(lat2)) * (lon1 - lon2)\n",
    "        return abs(area)\n",
    "    new_df['STORM_AREA_MILES'] = new_df.apply(lambda row: rect_area(row['BEGIN_LAT'], row['BEGIN_LON'], row['END_LAT'], row['END_LON']), axis=1)\n",
    "\n",
    "    # drop the begin and end lat and lon columns\n",
    "    new_df = new_df.drop(columns=['BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON'])\n",
    "\n",
    "\n",
    "\n",
    "    # calculate the total damage by converting the damage property column to a numeric value. \n",
    "    # The damage property column is in the format of a string with a number followed by a letter (K, M, B) which represents the magnitude of the damage. \n",
    "    # keep missing values\n",
    "    def convert_damage(damage):\n",
    "        if pd.isna(damage):\n",
    "            return np.nan\n",
    "        elif damage.endswith('K'):\n",
    "            return float(damage[:-1]) * 1e3\n",
    "        elif damage.endswith('M'):\n",
    "            return float(damage[:-1]) * 1e6\n",
    "        elif damage.endswith('B'):\n",
    "            return float(damage[:-1]) * 1e9\n",
    "    new_df['DAMAGE_PROPERTY'] = new_df['DAMAGE_PROPERTY'].apply(convert_damage)\n",
    "\n",
    "\n",
    "    \n",
    "    # calculate the duration of the storm by using begin time and end time columns which are in military time (hhmm)\n",
    "    def calculate_duration(row):\n",
    "        begin_time = row['BEGIN_TIME']\n",
    "        end_time = row['END_TIME']\n",
    "\n",
    "        # pad the time strings with zeros if they are less than 4 characters long\n",
    "        begin_time = str(begin_time).zfill(4)\n",
    "        end_time = str(end_time).zfill(4)\n",
    "\n",
    "        begin_hours = int(begin_time[:2]) \n",
    "        end_hours = int(end_time[:2]) \n",
    "        begin_minutes = int(begin_time[2:])\n",
    "        end_minutes = int(end_time[2:])\n",
    "\n",
    "        duration = (end_hours * 60 + end_minutes) - (begin_hours * 60 + begin_minutes)\n",
    "        if duration < 0:\n",
    "            duration += 24 * 60  # Adjust for storms that last past midnight\n",
    "        return duration  # Return duration in minutes\n",
    "    new_df['DURATION_MINUTES'] = new_df.apply(calculate_duration, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    # keep event types: ones with flood in the name, Hail, heavy rain, high wind, lightning, strong wind, thunderstorm wind, and tornado\n",
    "    new_df = new_df[new_df['EVENT_TYPE'].str.contains('FLOOD|HAIL|HEAVY RAIN|HIGH WIND|LIGHTNING|STRONG WIND|THUNDERSTORM WIND|TORNADO', case=False, na=False)]\n",
    "    # drop marine event types\n",
    "    new_df = new_df[~new_df['EVENT_TYPE'].str.contains('Marine', case=False, na=False)]\n",
    "\n",
    "\n",
    "\n",
    "    # get month from yearmonth column and add it as a new column called 'MONTH'\n",
    "    new_df['MONTH'] = new_df['BEGIN_YEARMONTH'].astype(str).str[4:6].astype(int)\n",
    "    # drop first 6 columns\n",
    "    new_df = new_df.drop(columns=new_df.columns[:6])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # combine state cz fips and pad with zeros on left to ensure they are 5 digits long. Add a new column called 'FIPS' to the dataframe\n",
    "    new_df['FIPS'] = new_df['STATE_FIPS'].astype(str) + new_df['CZ_FIPS'].astype(str).str.zfill(3)\n",
    "    # drop STATE_FIPS and CZ_FIPS columns\n",
    "    new_df = new_df.drop(columns=['STATE_FIPS', 'CZ_FIPS'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # keep only states in the continental US\n",
    "    non_continental_states = ['ALASKA', 'HAWAII', 'PUERTO RICO', 'GUAM', 'VIRGIN ISLANDS', 'AMERICAN SAMOA', 'NORTHERN MARIANA ISLANDS'] # keeping the district of columbia\n",
    "    new_df = new_df[~new_df['STATE'].isin(non_continental_states)]\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a1ffe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[            'ILLINOIS',             'VIRGINIA',            'WISCONSIN',\n",
       "             'NEBRASKA',             'NEW YORK',             'MISSOURI',\n",
       "               'OREGON',           'WASHINGTON',            'LOUISIANA',\n",
       "                 'IOWA',           'CALIFORNIA',                'MAINE',\n",
       "             'ARKANSAS',          'MISSISSIPPI',             'OKLAHOMA',\n",
       "                 'UTAH',        'NEW HAMPSHIRE',         'PENNSYLVANIA',\n",
       "         'RHODE ISLAND',              'ALABAMA',        'MASSACHUSETTS',\n",
       "             'COLORADO',               'KANSAS',         'SOUTH DAKOTA',\n",
       "              'WYOMING',       'NORTH CAROLINA',              'FLORIDA',\n",
       "              'ARIZONA',            'MINNESOTA',                'TEXAS',\n",
       "           'NEW MEXICO',              'GEORGIA',             'KENTUCKY',\n",
       "                 'OHIO',             'MICHIGAN',               'NEVADA',\n",
       "         'NORTH DAKOTA',              'MONTANA',            'TENNESSEE',\n",
       "             'MARYLAND',        'WEST VIRGINIA',       'SOUTH CAROLINA',\n",
       "              'INDIANA',                'IDAHO',             'DELAWARE',\n",
       "           'NEW JERSEY',              'VERMONT',          'CONNECTICUT',\n",
       " 'DISTRICT OF COLUMBIA']\n",
       "Length: 49, dtype: str"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = clean_storm(r\"rawData\\2023\\StormEvents_details-ftp_v1.0_d2023_c20260116.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80479fec",
   "metadata": {},
   "source": [
    "Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c4aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39e66711",
   "metadata": {},
   "source": [
    "Median Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd102415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eee7a05b",
   "metadata": {},
   "source": [
    "Relative Oceanic Nino Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c04249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_roni(csv):\n",
    "    # read in the csv file\n",
    "    df = pd.read_csv(csv)\n",
    "\n",
    "    # set the year as the index\n",
    "    df = df.set_index('Year')\n",
    "\n",
    "    # rename the columns DJF becomes december, january, and february\n",
    "    df = df.rename(columns={'DJF': 'DECEMBER_JANUARY_FEBRUARY'})\n",
    "    df = df.rename(columns={'JFM': 'JANUARY_FEBRUARY_MARCH'})\n",
    "    df = df.rename(columns={'FMA': 'FEBRUARY_MARCH_APRIL'})\n",
    "    df = df.rename(columns={'MAM': 'MARCH_APRIL_MAY'})\n",
    "    df = df.rename(columns={'AMJ': 'APRIL_MAY_JUNE'})\n",
    "    df = df.rename(columns={'MJJ': 'MAY_JUNE_JULY'})\n",
    "    df = df.rename(columns={'JJA': 'JUNE_JULY_AUGUST'})\n",
    "    df = df.rename(columns={'JAS': 'JULY_AUGUST_SEPTEMBER'})\n",
    "    df = df.rename(columns={'ASO': 'AUGUST_SEPTEMBER_OCTOBER'})\n",
    "    df = df.rename(columns={'SON': 'SEPTEMBER_OCTOBER_NOVEMBER'})\n",
    "    df = df.rename(columns={'OND': 'OCTOBER_NOVEMBER_DECEMBER'})\n",
    "    df = df.rename(columns={'NDJ': 'NOVEMBER_DECEMBER_JANUARY'})\n",
    "\n",
    "    # split each column with the month names into three separate columns with the month name as the column name and the value as the value.\n",
    "    # if month exists already add the value to the existing column.\n",
    "    month_columns = ['DECEMBER_JANUARY_FEBRUARY', 'JANUARY_FEBRUARY_MARCH', 'FEBRUARY_MARCH_APRIL', 'MARCH_APRIL_MAY', 'APRIL_MAY_JUNE', 'MAY_JUNE_JULY', 'JUNE_JULY_AUGUST', 'JULY_AUGUST_SEPTEMBER', 'AUGUST_SEPTEMBER_OCTOBER', 'SEPTEMBER_OCTOBER_NOVEMBER', 'OCTOBER_NOVEMBER_DECEMBER', 'NOVEMBER_DECEMBER_JANUARY']\n",
    "    for month_column in month_columns:\n",
    "        months = month_column.split('_')\n",
    "        for month in months:\n",
    "            col_name = month\n",
    "            if col_name in df.columns:\n",
    "                df[col_name] += df[month_column]\n",
    "            else:\n",
    "                df[col_name] = df[month_column]\n",
    "    \n",
    "        # drop the original column\n",
    "        df = df.drop(columns=[month_column])\n",
    "\n",
    "    # divide all month columns by 3 to get the average value for each month\n",
    "    df = df.div(3)\n",
    "\n",
    "    # # combine duplicate columns by taking the mean of the duplicate columns\n",
    "    # df = df.groupby(df.columns, axis=1).mean()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "98c33396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DECEMBER</th>\n",
       "      <th>JANUARY</th>\n",
       "      <th>FEBRUARY</th>\n",
       "      <th>MARCH</th>\n",
       "      <th>APRIL</th>\n",
       "      <th>MAY</th>\n",
       "      <th>JUNE</th>\n",
       "      <th>JULY</th>\n",
       "      <th>AUGUST</th>\n",
       "      <th>SEPTEMBER</th>\n",
       "      <th>OCTOBER</th>\n",
       "      <th>NOVEMBER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>-0.966667</td>\n",
       "      <td>-1.200000</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>-1.233333</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.433333</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.533333</td>\n",
       "      <td>-0.633333</td>\n",
       "      <td>-0.766667</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-0.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DECEMBER   JANUARY  FEBRUARY     MARCH     APRIL       MAY      JUNE  \\\n",
       "Year                                                                         \n",
       "1950 -0.966667 -1.200000 -1.333333 -1.233333 -1.166667 -1.066667 -0.833333   \n",
       "1951  0.333333 -0.166667 -0.500000 -0.166667  0.133333  0.400000  0.566667   \n",
       "1952  0.200000  0.333333  0.400000  0.333333  0.266667  0.166667  0.033333   \n",
       "1953  0.666667  0.600000  0.533333  0.633333  0.700000  0.766667  0.766667   \n",
       "1954 -0.200000  0.200000  0.433333  0.033333 -0.300000 -0.466667 -0.533333   \n",
       "\n",
       "          JULY    AUGUST  SEPTEMBER   OCTOBER  NOVEMBER  \n",
       "Year                                                     \n",
       "1950 -0.600000 -0.433333  -0.400000 -0.466667 -0.600000  \n",
       "1951  0.733333  0.866667   1.033333  1.066667  1.000000  \n",
       "1952 -0.033333  0.033333   0.100000  0.100000  0.066667  \n",
       "1953  0.733333  0.733333   0.766667  0.800000  0.800000  \n",
       "1954 -0.633333 -0.766667  -0.833333 -0.800000 -0.733333  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_roni = clean_roni(r\"rawData\\2023\\RONI.csv\")\n",
    "test_roni.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479bc672",
   "metadata": {},
   "source": [
    "Temperature Anomoly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8942bf39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
